\section{Introduction}
\label{sec:introduction}

Over the past few years, modern hardware capabilities have improved to the point where workloads in the field of \acs{ML} that were previously computationally infeasible, are now possible. One such sub-field of \acs{ML} is \acp{ANN}. The performance and capabilities of \acp{ANN} is largely influenced by the learning process used. As such, a popular field of focus for studying \acp{ANN} is the process by which these models are trained. \acp{ANN} are trained by optimisation algorithms known as heuristics.

Many different heuristics have been developed and used to train \acp{ANN}~\cite{ref:gudise:2003, ref:rakitianskaia:2012, ref:montana:1989}. Each of these heuristics have different search behaviours, characteristics, strengths and weaknesses. Finding the best heuristic to train the \acs{ANN} is required in order to yield optimal results. This process is often non-trivial and could be a time-consuming exercise.  Selection of the best heuristic to train \acp{ANN}, is often problem specific~\cite{ref:allen:1996, ref:drake:2020, ref:pillay:2018}.

A recent suggestion related to the field of \index{meta-learning}meta-learning is to dynamically select and/or adjust the heuristic used throughout the training process. This approach focuses on the hybridisation of learning paradigms. One such form of hybridisation of learning paradigms is that of hybridisation of different \textit{heuristics} as they are applied to some optimisation problem~\cite{ref:burke:2013}. These methods are referred to as \acfp{HH} and focus on finding the best heuristic in \textit{heuristic space} to solve a specific problem.

In the general context of optimisation, many different types of \acp{HH} have been implemented and applied to many different problems. However, research on the application of \acp{HH} in the context of \acs{ANN} training is scarce. \citeauthor{ref:nel:2021}~\cite{ref:nel:2021} provides the first research in this field, applying a \acs{HH} to \acs{FFNN} training.

This research takes a particular interest in developing a population-based, selection \acs{HH} that makes use of probability theory and Bayesian statistical concepts to guide the heuristic selection process. This research presents the novel \Acf{BHH}, a new high-level heuristic that utilises a statistical approach, referred to as \index{Bayesian analysis}\textit{Bayesian analysis}, which combines prior information with new evidence to the parameters of a selection probability distribution. This selection probability distribution is the mechanism by which the \acs{HH} selects appropriate heuristics to train \acp{FFNN} during the training process. This process takes place dynamically and during the training process (online learning).

The remainder of this article is structured as follows: Section~\ref{sec:anns} provides background information on \acp{ANN}. Section~\ref{sec:heuristics} provides details on various types of heuristics that have been used to train \acp{FFNN}. Section~\ref{sec:hhs} presents background information on \acp{HH} and \index{meta-learning}meta-learning. Section~\ref{sec:probability} presents background information on probability theory. Section~\ref{sec:bhh} presents the developed \Acs{BHH}. Section~\ref{sec:methodology} presents a detailed description of the empirical process and the setup of each experiment. Section~\ref{sec:results} provides and discusses the results of the empirical study. Section~\ref{sec:conclusion} summarises the research that is done along with a brief overview of the findings made throughout the research process.
