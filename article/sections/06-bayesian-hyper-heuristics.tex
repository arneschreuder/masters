\section{Bayesian Hyper-Heuristics}
\label{sec:bhh}

This section presents the novel \acs{BHH}. The general concept of the \acs{BHH} can be summarised as follows: The \acs{BHH} implements a high-level heuristic selection mechanism that learns to select the best heuristic from a pool of low-level heuristics, to apply to a population of entities, each implementing a candidate solution to a \acs{FFNN}, with the intent of both optimising the underlying \acs{FFNN} and \acs{FFNN} training process. The \acs{BHH} does so by learning the probability that a given heuristic will perform well at a given stage in the \acs{FFNN} training process. These probabilities are then used as heuristic selection probabilities in the next step of the training process.

According to the classification scheme for \acp{HH} by \citeauthor{ref:burke:2010} \cite{ref:burke:2010}, the \acs{BHH} is a population-based, meta-hyper-heuristic that utilises selection and perturbation of low-level heuristics in an online learning fashion.

The reader is referred to \cite{ref:schreuder:2022} for an illustration of the high-level architecture of the \acs{BHH} as well as the high level pseudo-code implementation of the \acs{BHH}. Discussions follow on the most important components of the \acs{BHH}.

\subsection{Heuristic Pool}\label{sec:bhh:heuristic_pool}

Generally speaking, the heuristic pool is a collection of low-level heuristics under consideration by the \acs{BHH}. The heuristic pool contains the set of low-level heuristics that, together with their performance information, make up the \text{heuristic space}. Importantly, the heuristic pool must consist of a diverse set of low-level heuristics with varying capabilities. This research takes an interest in including both gradient-based heuristics as well as \acp{MH} in the heuristic pool. This approach is referred to as a \textit{multi-method} approach.

\subsection{Proxies}\label{sec:bhh:heuristic:proxies}

The concept of proxies arise from the sparsity of state as maintained by different heuristics. Since heuristics maintain (possibly) different states, there is an uncertainty of state transition when switching between heuristics. A solution to state indifference is to \textit{proxy} heuristic state update operations. State is then maintained in two parts: primary and proxied state. Primary state refers to the state that is originally maintained by a heuristic. While proxied state refers to the state that is not directly maintained by the heuristic, but can be updated by outsourcing the required state update operation to another heuristic. The \acs{BHH} thus incorporates a mapping of proxied state update operations. Similar to before, the reader is referred to \cite{ref:schreuder:2022} for details on the mapped proxied state update operations.

\subsection{Entity Pool}\label{sec:bhh:entity_pool}

The entity pool refers to a collection or \textit{population} of \textit{entities} that each represent a candidate solution to the underlying \acs{FFNN} being trained. The \acs{BHH} selects from the heuristic pool a low-level heuristic to be applied to an individual entity. The outcome of this selection process is a mapping table that tracks which heuristic has been selected for which entity. These heuristic-entity combinations are applied to the underlying \acs{FFNN}. The \acs{BHH} tracks the performance of each of these combinations throughout the training process in a performance log.

Entities represent candidate solutions to the model's trainable parameters (weights) and other heuristic-specific state parameters. These state parameters are referred to as \textit{local} state. Entities are treated as physical \textit{particles} in a hyper-dimensional search environment. Entities model concepts from physics. For example, the candidate solution is represented as the entity's position, and velocity and acceleration is analogous to the gradient and momentum of the entity respectfully. Examples of entity state parameters, as derived from various low-level heuristics, include entity position, velocity, gradient, position delta, first and second moments of the gradient, the loss, personal best positions, losses, and so on. The entity state parameters are updated by the associated heuristic.

The population state refers to a collection of parameters that are shared between the entities in the population. Population state is also referred to as \textit{global} state and represents the population's memory. The population state generally contains state parameters that are of importance to multiple heuristics, and usually tracks the state of the population and not individual heuristic. Some examples of population state that can arise from different heuristics include the population of entities themselves, the global best entity found so far, the overall best loss achieved thus far, and so on.

\subsection{Performance Log}\label{sec:bhh:performance_log}

Heuristic selection probability is calculated based on heuristic-entity performance over time. Evidence of heuristic-entity performance is thus required for the \acs{BHH} to learn. Historical heuristic-entity performance outcomes are stored in a performance log. The performance log tracks information such as the current step, selected heuristic, associated entity, the loss achieved and so on. Since the performance log can become very big, only a sliding window of the performance history is maintained at each step in the learning process. The sliding window is also referred to as a \textit{replay} window/buffer.

\subsection{Credit Assignment Strategy}
\label{sec:bhh:credit_assignment_strategy}

The credit assignment strategy is a mechanism that assigns a discrete credit indicator to heuristics that perform well, based on their performance metrics such as loss. The credit assignment strategy implements a component of the ``move acceptance'' process as proposed by \citeauthor{ref:ozcan:2006} \cite{ref:ozcan:2006,ref:ozcan:2008} and addresses the credit assignment problem as discussed by \citeauthor{ref:burke:2010} \cite{ref:burke:2010}. A good credit assignment strategy will correctly allocate credit to the appropriate heuristic-entity combination. This research implements the following credit assignment strategies to choose from: \textit{ibest} (iteration best), \textit{pbest} (personal best), \textit{gbest} (global best), \textit{rbest} (replay window best), and \textit{symmetric}, where credit is assigned to all entity-heuristic combinations, regardless of their performance.

\subsection{Selection Mechanism}\label{sec:bhh:selection_mechanism}

The \acs{BHH} implements a probabilistic, predictive model based on the fundamentals of the Na\"{\i}ve Bayes algorithm. The \acs{BHH} thus distinguishes between the following events: \textbf{$\boldsymbol{H}$}, the event of observing \textit{heuristics}, \textbf{$\boldsymbol{E}$}, the event of observing \textit{entities}, \textbf{$\boldsymbol{C}$}, the event of observing \textit{credit assignments} that indicate that the credit assignment \textit{performance criteria} are met. By Bayes' theorem, the selection mechanism implemented by the \acs{BHH} is given as

\begin{equation}
	\label{eq:bhh:selection_mechanism:predictive_model_prop_to}
	\begin{split}
		P(\boldsymbol{H} \vert \boldsymbol{E}, \boldsymbol{C}; \boldsymbol{\theta}, \boldsymbol{\phi}, \boldsymbol{\psi}) &\propto P(\boldsymbol{E} \vert \boldsymbol{H}; \boldsymbol{\phi}) P(\boldsymbol{C} \vert \boldsymbol{H}; \boldsymbol{\psi}) P(\boldsymbol{H} \vert \boldsymbol{\theta})
	\end{split}
\end{equation}

The predictive model thus models the \textit{proportional} probability of the event (selection of) heuristic $\boldsymbol{H}$, given allocation to entity $\boldsymbol{E}$ and credit requirement $\boldsymbol{C}$, parameterised by sampled $\boldsymbol{\theta} \vert \boldsymbol{\alpha} \sim Dir(\boldsymbol{\alpha}; K)$, $\boldsymbol{\phi} \vert \boldsymbol{\beta} \sim Dir(\boldsymbol{\beta}; K)^{J}$ and $\boldsymbol{\psi} \vert \gamma_{1}, \gamma_{0}  \sim Beta(\gamma_{1}, \gamma_{0})$. In the aforementioned, $K$ is the heuristic pool size, $J$ is the entity pool size and the indices $1$ and $0$ refers to success and failure parameters respectively. The concentration parameters $\boldsymbol{\alpha}$, $\boldsymbol{\beta}$, $\gamma_{1}$ and $\gamma_{0}$ denote the prior beliefs of the \acs{BHH}. Similar to before, the reader is referred to \cite{ref:schreuder:2022} for the mathematical derivation of the selection mechanism.

\subsection{Optimisation Step}\label{sec:bhh:optimisation_step}

The intent of the \acs{BHH} is to gather evidence that can be used to update prior beliefs about which heuristics perform well during training. These beliefs are represented by the concentration parameters $\boldsymbol{\alpha}$, $\boldsymbol{\beta}$, $\gamma_{1}$ and $\gamma_{0}$. A change in prior beliefs is represented by a change in these concentration parameters. Specifically, it can be said that the optimisation process implemented by the \acs{BHH} updates \textit{pseudo counts} of events that are observed in the performance logs. These pseudo counts track the occurrence of a heuristic, an entity, and resulting performance of these two elements. Through the credit assignment strategy, these pseudo counts are biased towards entity-heuristic combinations that meet performance requirements and yield credit allocations.

Generally, there are two different techniques that are used to train Na√Øve Bayes classifiers. The frequentist approach implements \acf{MLE} and the Bayesian approach implements \acf{MAP}.


\subsubsection{Maximum Likelihood Estimation}\label{sec:bhh:optimisation_step:mle}

The values for $\boldsymbol{\theta}$, $\boldsymbol{\phi}$ and $\boldsymbol{\psi}$ can be estimated by \acs{MLE} as follows:

\begin{equation}
	\label{eq:bhh:optimisation_step:mle:theta}
	\begin{split}
		\hat{\theta}_{k} = E[\theta_{k}] = \frac{N_{k}}{N}
	\end{split}
\end{equation}

\begin{equation}
	\label{eq:bhh:optimisation_step:mle:phi}
	\begin{split}
		\hat{\phi}_{j,k} = E[\phi_{j,k}] = \frac{N_{j,k}}{N_{j}}
	\end{split}
\end{equation}

\begin{equation}
	\label{eq:bhh:optimisation_step:mle:psi}
	\begin{split}
		\hat{\psi}_{k} = E[\psi_{k}] = \frac{N_{1,k}}{N_{k}}
	\end{split}
\end{equation}


\subsubsection{Maximum A Posteriori Estimation}\label{sec:bhh:optimisation_step:map}

Another approach to optimise the values for $\hat{\theta}_{k}$, $\hat{\phi}_{j,k}$ and $\hat{\psi}_{k}$ is to optimise the parameters by their probability distributions' parameters. This process is referred to as \textit{Bayesian analysis}. Bayesian analysis makes use of the \textit{posterior} probability distribution. The concentration update operations yielded by \acs{MAP}, are then be given as

\begin{equation}
	\label{eq:bhh:optimisation_step:map:alpha_update_operation}
	\begin{split}
		\alpha_{k}(t+1) = N_{k} + \alpha_{k}(t)
	\end{split}
\end{equation}

\begin{equation}
	\label{eq:bhh:optimisation_step:map:beta_update_operation}
	\begin{split}
		\beta_{j,k}(t+1) = N_{j,k} + \beta_{j,k}(t)
	\end{split}
\end{equation}

\begin{equation}
	\label{eq:bhh:optimisation_step:map:gamma1_update_operation}
	\begin{split}
		\gamma_{1,k}(t+1) = N_{1,k} + \gamma_{1,k}(t)
	\end{split}
\end{equation}

\begin{equation}
	\label{eq:bhh:optimisation_step:map:gamma2_update_operation}
	\begin{split}
		\gamma_{2,k}(t+1) = N_{0,k} + \gamma_{2,k}(t)
	\end{split}
\end{equation}

It can be said that the \acs{BHH} implements a Gaussian process \cite{ref:gortler:2019}. Since the reselection of heuristics happens at regular intervals, the outcome of a selection in one iteration may influence the outcome of another in the next iteration, making the implementation of the \acs{BHH} a \acs{HMM} \cite{ref:rabiner:1986}.


\subsection{Hyper-Parameters}\label{sec:bhh:hyper_parameters}

The following hyper-parameters are implemented by the \acs{BHH}: the \textit{heuristic pool} configures the type of heuristics included in the heuristic pool as gradient-only, meta-heuristic-only or all heuristics, the \textit{population size} specifies the number of entities in the entitiy pool, the \textit{credit assignment strategy} specifies which credit assignment strategy to use, the \textit{reselection interval} determines the frequency of heuristic reselection, the \textit{replay window size} determines the maximum size of the performance log, the \textit{reanalysis interval} determines the frequency at which Bayesian analysis is applied, the \textit{burn in window size} determines the size of an initial window where experience is simply gathered without reanalysis, and finally, \textit{discounted rewards} and \textit{normalisation} flags toggle scaling modifiers on the credit assignment strategies, backwards in the performance log.
