\begin{highlights}
	\item A novel \acf{HH} selection operator is used that focuses on using Bayesian statistics to calculate the probability that a heuristic should be selected in order to efficiently train \acfp{FFNN}. The resulting \acs{HH} is referred to as the \acf{BHH}.

	\item The results of the empirical study show with statistical significance and certainty that the \acs{BHH} performs generally well on multiple problems. It is shown that, for each problem, the \acs{BHH} performance is comparable to the best low-level heuristics included in the heuristic selection pool.

	\item The results of the empirical study show that the \acs{BHH} is able to select the best heuristic to train \acp{FFNN} in general. This relieves researchers from the burden of having to do this selection process manually through trial and error.

	\item The results of the empirical study show that the \acs{BHH}, given a diverse set of lower-level heuristics, will generally produce good results when applied to multiple problems at the same time.

	\item Finally, the results of the empirical study show that the \acs{BHH} is capable of utilising \textit{a priori} \footnote{Latin word, meaning ``from what comes before''.} knowledge in which a predefined selection bias is used for heuristics that are known to be well suited for certain problems.
\end{highlights}