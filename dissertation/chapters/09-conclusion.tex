\chapter{Conclusion}
\label{chap:conclusion}

\begin{quote}
      \textit{
            I am sorry to have made such a long speech, but I did not have time to make a shorter one. - Winston Churchill
      }
\end{quote}

Finally, the research objectives that have been set out in this dissertation must be concluded. This chapter provides a summary of the research that has been done.

The remainder of the chapter is structured as follows:

\begin{itemize}
      \item \textbf{Section \ref{sec:conclusion:research_goals}} provides a review of the problem statement, objectives and motivations behind the research.

      \item \textbf{Section \ref{sec:conclusion:background_info}} summarises the background information that was covered.

      \item \textbf{Section \ref{sec:conclusion:bhh}} provides a brief recap of the \ac{BHH} and its implementation.

      \item \textbf{Section \ref{sec:conclusion:methodology}} provides a brief recap of the methodology and the empirical process that was followed.

      \item \textbf{Section \ref{sec:conclusion:results}} summarises the research findings.

      \item \textbf{Section \ref{sec:conclusion:further_research}} discuss further research opportunities.

      \item \textbf{Section \ref{sec:conclusion:documentation_and_data}} briefly discusses some supplementary and supporting material related to the research, as made available by the authors either as external sources or in the appendices of this dissertation.

      \item Finally, \textbf{Section \ref{sec:conclusion:closing_statements}} provides the closing statements of the dissertation.
\end{itemize}

\section{Reviewing Research Objectives}
\label{sec:conclusion:research_goals}

This section briefly reviews the problem statement, motivations and research objectives that was set out in Chapter \ref{chap:introduction} of this dissertation.

The main area of focus for this research stems from the problem statement which identified the difficult and tedious problem of heuristic selection for \ac{FFNN} training. Often times this process is non-trivial and very time-consuming. It has been identified that there is no easy way to know which heuristic to select to train \acp{FFNN}. Traditionally, an iterative approach of trial-and-error was followed. This process involves a tedious process of careful consideration and selection, often at the expense of the researcher's resources.  This research has identified the possibility of using a relatively new approach, referred to as \acp{HH} to automate this selection process. \ac{HH} has been shown to provide a general solution to this problem. The consequences of such approach being successful could provide a mechanism that saves a lot of time and could provide a more generalised solution to heuristic selection.

Investigation was done into the landscapes of existing solutions to train \acp{FFNN} as well as \acp{HH}. Though there exists many applications of \acp{HH} there are little to no published work on using \acp{HH} to train \acp{FFNN}. The only work that was found include the work by~\citeauthor{ref:nel:2021}~\cite{ref:nel:2021}.

Other existing techniques from other problem domains were investigated. \ac{RL}, meta-learning, online, one-shot and probabilistic learning approached were considered. Bayesian probability theory showed promise and the \Ac{BHH} was conceptualised.

The research objectives were defined and are summarised as follows:

\begin{itemize}
      \item Conduct literature studies on all related topics that are relevant to the development of the \ac{BHH}. These include \ac{ANN}, \index{heuristic}heuristics/optimisers, meta-learning, \acp{HH}, probability theory and Bayesian statistics.

      \item Develop a novel \ac{BHH} that has both a selective and perturbative element. For the selection mechanism, Bayesian statistics and \ac{MAP} is used. For the perturbative element, proxied low-level \index{heuristic}heuristic update steps are used.

      \item Conduct an empirical study to show that the \ac{BHH} is able to train \acp{FFNN} effectively on a number of different datasets.

      \item Conduct an empirical study to study the behavioural characteristics of the \ac{BHH}.

      \item Conduct an empirical study to critically evaluate the performance of the \ac{BHH} to those of traditional, low-level \index{heuristic}heuristic when training \acp{FFNN} on a number of different datasets.

      \item Conduct an empirical study to evaluate variants of the \ac{BHH} to study the impacts of various design decisions on the outcomes of the \ac{BHH}.

      \item Provide a statistically sound evaluation of outcomes with statistical significance tests driving the conclusions of the outcomes.
\end{itemize}

As one can see, the research set out to do in this dissertation was quite extensive and also identifies many different opportunities for future research.

The next sections aim to provide brief summaries of the work that was done, followed by a conclusion of the outcomes of each.

\section{Summary of Background Information}
\label{sec:conclusion:background_info}

Chapters \ref{chap:introduction} - \ref{chap:probability} provided the reader with background information that is necessary to understand the components that are discussed and developed in this work. These chapters respectively provided background information, literature reviews and landscape analyses into \acp{ANN}, \index{heuristic}heuristics/optimisers, \acp{HH} and meta-learning, probability theory and Bayesian statistics.

It should be mentioned that there are many resources available on the above mentioned topics in their own right. However, the intersection of these topics, especially \acp{ANN} and \acp{HH} are close to non-existent and calls for much more research and publication. This dissertation aims to provide a manifesto of these topics and how they are bring together to show that \acp{HH} can be used to train \acp{FFNN}.

From these topics, it can be concluded that the necessary background information that was provisioned for in the objectives for the dissertation have been provided. The next section gives a summary of the novel \ac{BHH} that was developed.


\section{Summary of Bayesian Hyper-Heuristics}
\label{sec:conclusion:bhh}

The main takeaway point from this dissertation is the development of a novel \ac{BHH}. Chapter \ref{chap:bhh} provides the details and implementation of the \ac{BHH} and provides the reader with various design decisions that could control/affect the outcomes of the \ac{BHH}.

It was shown how the \ac{BHH} implements a Bayesian probabilistic model and makes use of online learning to select \index{heuristic}heuristics dynamically throughout the training process. This probabilistic model forms the selection mechanism for the \ac{BHH}.

Furthermore, it is shown that selection alone is not enough and that a measure of transition between \index{heuristic}heuristics is needed. Entity and \index{heuristic}heuristic state and state-manipulation formed the cornerstone of this topic. A technique that deconstructs \index{heuristic}heuristics into their initialisation and update steps is proposed. This technique then allows for the proxying of update step operations as they are required by different \index{heuristic}heuristics. Though this solves the transition problem between \index{heuristic}heuristics, is has been indicated that does not guarantee stable search processes. This does raise opportunities for further research which is summarised below in Section \ref{sec:conclusion:further_research}.

The simplicity of the \ac{BHH} and various challenges related to it have been highlighted. Of these challenge include:

\begin{itemize}
      \item Catering for overfitting by early stopping conditions.
      \item Catering for invalid selections.
      \item Catering for invalid or stale entity and \index{heuristic}heuristic states.
      \item Catering for mode-collapse where a \index{heuristic}heuristic is either always selected or never selected.
      \item Catering for a trade-off between exploration and exploitation.
\end{itemize}

After the development of the \ac{BHH}, the authors presented the methodology used to execute the empirical process. The details of which is summarised in the next section.



\section{Summary of Methodology}
\label{sec:conclusion:methodology}

As discussed above, the research objectives defined a number of empirical tests to be executed. Each one of the empirical tests is referred to as an experimental group. Various experimental groups have been identified and is listed below:

\begin{itemize}
      \item A case-study on the behaviour of the \ac{BHH} during training and testing to understand the workings of the \ac{BHH} and to see if the \ac{BHH} is able to train \acp{FFNN}.
      \item A comparative analysis between the performance of standalone \index{heuristic}heuristics and the baseline \ac{BHH} when training \acp{FFNN}.
      \item A comparative analysis between variants of the \ac{BHH} that include:
            \begin{itemize}
                  \item Different \index{heuristic}heuristic pool configurations.
                  \item Different population sizes.
                  \item Different credit assignment strategies.
                  \item Different reselection window sizes.
                  \item Different replay window sizes.
                  \item Different reanalysis window sizes.
                  \item Different burn in window sizes.
                  \item Enabling and disabling normalisation of pseudo counts in the performance log.
                  \item Enabling and disabling discounted rewards of pseudo counts in the performance log.
            \end{itemize}
\end{itemize}

Each experimental group is run against a set of 15 datasets, consisting of regression and classification problems, split between uni- and multimodal problems. Each experimental group is repeated over 30 runs for statistical certainty. The statistical analysis process was discussed and ANOVA, post hoc Tukey, independent T-test and Kruskal-Wallis formed part of the statistical test repertoir.

In order to allow for the studying of the \ac{BHH} even after training has saturated and overfitting has occured, all experimental groups are run for 30 epochs, way more than what has been empirically found to be necessary. This also meant that no early stopping conditions were used.

The next section provides a summary of all the results, findings and conclusions related to the empirical process is given next.

\section{Summary of Results}
\label{sec:conclusion:results}

All empirical tests where successfully executed and statistically evaluate as described in the methodology presented in Chapter \ref{chap:methodology}. From these evaluations a number of conclusions are made, each described briefly in the sub-sections below:

\subsection{\ac{BHH} behavioural case study}
\label{sec:conclusion:results:summary:case_study}

For this experimental group it was found that the \ac{BHH} is able to train \acp{FFNN} relatively well. It was shown how the \ac{BHH} is able to learn and that the learning is in a positive direction towards the overall objectives of the \ac{BHH}. Furthermore, it was shown in isolation that both the selection mechanism as well as the perturbative component of the \ac{BHH} was successful in their own rights, resulting in a \ac{HH} that is able to select and combine \index{heuristic}heuristics as needed.

It was shown how the \ac{BHH} drastically overfits at some point during training for a number of datasets. Although it is known that early stopping conditions would prohibit this from happening, other solutions have also been proposed. These include:

\begin{itemize}
      \item \index{heuristic}Heuristic selection acceptance criteria: where a selection is only deemed valid if it does indeed improve on performance.

      \item State reset: to avoid overshooting solutions due to momentum.

      \item Various techniques to balance exploration and exploitation.
\end{itemize}

Various example plots on training and test datasets have been provided and detailed plots of the inner-workings of the \ac{BHH} have been presented to support the findings and arguments.

\subsection{Standalone vs. \ac{BHH} Baseline}
\label{sec:conclusion:results:summary:standalone}

For this experimental group the baseline \ac{BHH} was found to perform relatively well in comparison to the standalone low-level \index{heuristic}heuristics. Overall the \ac{BHH} ranked 5th out of 11 with performances close to that of the best \index{heuristic}heuristics. Unfortunately, the \ac{BHH} was not entirely able to beat the best heuristics on all occasions, but did perform comparatively well in all cases. The empirical results, statistical tests, descriptive plots and plots of example runs are given to support findings and conclusions.

\subsection{\ac{BHH} Variant: Heuristic pool}
\label{sec:conclusion:results:summary:heuristic_pool}

For this experimental group, different configurations of \index{heuristic}heuristic pools were considered. Three different configurations were evaluated. It was found that the gradient-only \ac{BHH} variant performed significantly better than the configurations that included all of the heuristics and one that included only the meta-heuristics. It was shown that the inclusion of meta-heuristics cause the \ac{BHH} to overfit much more drastically due to the nature of their update step operations.

\subsection{\ac{BHH} Variant: Population Size}
\label{sec:conclusion:results:summary:population_size}

For this experimental group, various different population sizes are evaluated. It was found that the population size is largely problem-dependent. An interesting observation was made where some cases where shown where the relationship between population size and performance is not linear, but rather parabolic or even polynomial in some cases. This warrants for further investigation and could serve as a good opportunity for future research.

\subsection{\ac{BHH} Variant: Credit}
\label{sec:conclusion:results:summary:credit}

For this experimental group, various different credit assignment strategies were evaluated. It was found that the choice of credit assignment strategy to use is largely problem-dependent. Two cases were highlighted where symmetric credit assignment was preferred, which suggests that for that dataset \index{heuristic}heuristic selection doesn't matter, only the proxied update step operations are sufficient.

\subsection{\ac{BHH} Variant: Reselection}
\label{sec:conclusion:results:summary:reselection}

For this experimental group different reselection window sizes were evaluated. It was found that a larger reselection size is generally preferred. A bigger reselection window sizes lead to a longer timeframe to learn before reselection has to occur. The increase in number of samples of evidence, per entity-heuristic combination in the performance log is argued to be the reason for this. However, that means that the reselection and replay window size parameter are related. If the reselection window size is large, the replay window size should be large as well.

\subsection{\ac{BHH} Variant: Replay}
\label{sec:conclusion:results:summary:replay}

For this experimental group, different replay windows sizes were evaluated. It was found that the replay window is problem-dependent with some dataset preferring short memory and other preferring long memory. Take note of the relationship between the reselection, replay and reanalysis window sizes. The value of the one does influence the value of other and should be carefully selection together.

\subsection{\ac{BHH} Variant: Reanalysis}
\label{sec:conclusion:results:summary:reanalysis}

For this experimental group different reanalysis window sizes were evaluated. It was also found that the reanalysis window size is problem-dependent. Given the relationship between the reselection, replay and reanalysis window sizes, a suggestion to eliminate hyper-parameters is to remove the notion of reanalysis and merge with reselection. Reselection is shown to correlate with reanalysis and thus can be removed by just setting the reanalysis window size equal to the reselection size.

\subsection{\ac{BHH} Variant: Burn In}
\label{sec:conclusion:results:summary:burn_in}

For this experimental group different burn in window sizes were evaluated. It was found that in general no burn in is preferred, but some exceptions preferring just a very small burn in. In general is was shown that large burn in values are not good.

\subsection{\ac{BHH} Variant: Normalise}
\label{sec:conclusion:results:summary:normalise}

For this experimental group an empirical test was conducted to determine the effects of normalisation of pseudo counts in the performance log. The choice of this parameter was shown to be problem depedent.

\subsection{\ac{BHH} Variant: Discounted Rewards}
\label{sec:conclusion:results:summary:discounted_rewards}

It can be concluded that the outcomes of the empirical process were successful and that the scientific process has been followed accordingly. From this, it can be concluded that all of the objective of the dissertation have been met and that the research can be concluded. The next section provides a brief discussion of further research opportunities that stem from this work.

\section{Further Research}
\label{sec:conclusion:further_research}

Throughout this dissertation, many different opportunities have been identified for future research. This section contains a summmary of these topics.


\subsubsection{Prior Knowledge}

The \ac{BHH} initialises the concentrations for its distributions symmetrically (a value of 1 for all indices). Symmetric initialisation contains no prior bias and assumes uniform sampling at first. It has been identified that expert knowledge can be incorporated into the \ac{BHH} by carefully providing the initial concentration for the distributions. This research would then evaluate if such prior information has a positive impact on the outcomes of the \ac{BHH}.


\subsubsection{Early Stopping}

It has been shown that the \ac{BHH} suffers drastically from overfitting as the majority of learning happens during the first few epochs (large datasets have more mini-batch iterations per epoch) resulting in the majority of the training process, which span 30 epochs, to try recover from overfitting. Early stop was purposefully not utilised in this research in order to see how the \ac{BHH} would behave after training has saturated. Early stopping could provide valuable insight into the actual ranked performance of the \ac{BHH} since overfitting would then no longer be present and a ranked performance evaluation can be done at some point in time.

\subsubsection{Entity Search}

For this dissertation, even though the predictive model implemented by the \ac{BHH} includes entity consideration, it does not sample from an entity pool, but rather keeps the entire entity pool and just switch allocated heuristics. The \ac{BHH}, as is, can be used to learn which entities to select as well. The hypothesis is that this would result in better combinations of entities and heuristics, more often, which should have a positive effect on the outcomes of the \ac{BHH}

\subsubsection{Models}

For this dissertation, focus was put on training \acp{FFNN}. However, in theory one should be able to swap out \acp{FFNN} for any other mathematical model that can be optimised. Suggestions include \acp{DNN}, \acp{RNN} and dynamic optimisation problems.

\subsubsection{Credit Search}

Credit assignment in the context of this dissertation was has 2 outcomes, true and false. Therefore, credit assignment and by definition performance evaluation is modeled as a \index{binomial distribution} distribution with a \index{Beta probability distribution}Beta probability distribution as a prior probability distribution. Heuristic selection has multiple possible outcomes, yielding a index associated with a heuristic. Therefore, heuristic selection is modeled as a \index{multionomial}multinomial/\index{categorical}categorical with a dirichlet probability distribution as a prior probability distribution. Since the dirichlet-multinomial distributions are the multivariate extensions of the beta-binomial distributions, it show be possible to extend credit assignment to a multivariate version. A suggestion then is to learn which credit assignment to select. The results of this have show that credit assignment is problem-dependent. Therefore, include credit selection as part of the selection pool implemented by the \ac{BHH}. One could then include multiple strategies, each with varying exploration-exploitation trade-off.

\subsubsection{Selection Validation}

The intent behind a selection validation mechanism is to confirm that selections are successful before they are utilised. In other words, a small verification window where it is decided whether the outcomes of a selection mechanism was beneficial to the learning outcomes or not. These selection validations are based on an ``acceptance criterion'' that a selection has to pass before it is validated. Inclusion of a selection validation mechanism for the \ac{BHH} could yield interesting outcomes.

\subsubsection{Dynamic Reselection Window Size Strategies}

It was shown that generally larger reselection window sizes are required. It was shown that there is a relationship between the reselection, replay and reanalysis window sizes. There is an inherent trade-off between exploration and exploitation and therefore, investigation into dynamic sizing strategies could be prove to yield interesting outcomes.

\subsubsection{Heuristic Pools}

This dissertation only considered 3 different configurations of the heuristic pool. The following alternative  configurations could be considered:

\begin{itemize}
      \item Multiple of the same heuristic, but with different hyper-parameter values.
      \item Very large or very small heuristic pool sizes.
      \item Inclusion of black-box optimisers such as CMA-ES.
      \item Ensemble pools where the heuristic selection is a selection of a ensemble configuration.
\end{itemize}

\subsubsection{Parameter Pools}

Throughout this dissertation, many of the findings have been said to be "problem-dependent". A possible solution to this is to apply the \ac{BHH} then for all parameters, not just heuristics. This means to include hyper-parameters such as learning rate, which can be "learnt" during training. This eliminates a lot of the burden to tediously fine-tune and optimise hyper-params.

This could also provide opportunity to investigate other \ac{FFNN} paradigms such as neural architecture search (ref ???) by including various parameters, that describe the \ac{NN} architecture. The \ac{BHH} slection mechanism can then include these elements for learning as well.

\subsubsection{Models}

This dissertation focused on \acp{FFNN} as the underlying model to be trained. However, other models can also be considered.


\section{Documentation and Data}
\label{sec:conclusion:documentation_and_data}

All data, source code, logs, configurations, scripts and analysis is hosted at: \url{https://github.com/arneschreuder/masters.ai} with raw empirical data made available on Google Cloud project id: masters-363209.


\section{Closing Statements}
\label{sec:conclusion:closing_statements}

The research that is presented in this dissertation included the development and detailed analysis of a novel \ac{BHH}. This chapter presented a review of the research objectives. In conclusion it is found that all of the research objectives have been met. The empirical process was sound and the research outcome have been shown to be statistically significant. This concludes the research presented in this document
